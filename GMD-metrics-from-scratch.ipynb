{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manuscripts: Re-visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manuscripts, currently, mostly only provides us with aggregations of data such as average, cardinality and so on. It isn't flexible enough to let us play with data For example: sort the data by different filters and values. Here, we will be experimenting what all can be done with the metrics. None of the previously written code will be used here so as to look at different ways and basically redesign the current code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll still be looking at the [GMD metrics](https://github.com/chaoss/metrics/blob/master/2_Growth-Maturity-Decline.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "\n",
    "# analysis modules\n",
    "import pandas as pd\n",
    "\n",
    "# query and connection modules\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from elasticsearch_dsl import A, Q, Search\n",
    "from elasticsearch_dsl.query import Match, MultiMatch\n",
    "\n",
    "# utility and support modules\n",
    "import new_functions as nf\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser, relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the necessary variables\n",
    "es = Elasticsearch(\"http://localhost:9200/\")\n",
    "\n",
    "github_index = \"perceval_github\"\n",
    "git_index = \"perceval_git\"\n",
    "\n",
    "start_date = datetime(2014, 8, 1)\n",
    "start_date = start_date.isoformat() # \"2014-08-01\"\n",
    "end_date = datetime(2018, 5, 22)\n",
    "end_date = end_date.isoformat()\n",
    "\n",
    "max_size = 10000 # temporary hack to get all the values in the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of filters we will be looking at:\n",
    "\n",
    "Let's talk about the kind of filters we want while looking at the metrics. \n",
    "\n",
    "Can we look at the metrics by seggregating them according to:\n",
    "- Date?\n",
    " - days\n",
    " - weeks\n",
    " - months\n",
    " - years\n",
    "\n",
    "\n",
    "- Organizations?\n",
    " - if people from multiple organizations are a part of the project, then we might need to see how they play along and which org is having the most influence?\n",
    " \n",
    "\n",
    "- Authors?\n",
    " - What if we want all the issues by the authors that created them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of aggregations\n",
    "\n",
    "Aggregation structure will be as follows:\n",
    "parent-child aggregations will follow the path:\n",
    "- 0(parent) we are starting from zero because it'll make it easy for us to loop through multiple aggregations\n",
    "  - 0.1(child)\n",
    "    - 0.01(child's child)\n",
    "\n",
    "sibling-sibling aggregations will follow the path:\n",
    "- 0(sibling)\n",
    "- 1(sibling)\n",
    "- 2(sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue Resolution\n",
    "Goal: Identify how effective the community is at addressing issues identified by community partcipants.\n",
    "\n",
    "Name | Question | Implemented | Issue | PR | Visualisation \n",
    "--- | --- | --- | --- | --- | --- |\n",
    "[Open Issues](https://github.com/chaoss/metrics/tree/master/activity-metrics/open-issues.md) | What is the number of open issues? | Yes | None | None | No\n",
    "[Closed Issues](https://github.com/chaoss/metrics/tree/master/activity-metrics/closed-issues.md) | What is the number of closed issues? | Yes | None | None | No\n",
    "[Issue Resolution Efficiency](https://github.com/chaoss/metrics/tree/master/activity-metrics/issue-resolution-efficiency.md) | What is the number of closed issues/number of abandoned issues? | No | [wg-gmd#5](https://github.com/chaoss/wg-gmd/issues/5) | None | No\n",
    "[Open Issue Age](https://github.com/chaoss/metrics/tree/master/activity-metrics/open-issue-age.md) | What is the the age of open issues? | Yes | None | None | No\n",
    "[First Response to Issue Duration](https://github.com/chaoss/metrics/tree/master/activity-metrics/first-response-to-issue-duration.md) | What is the duration of time for a first response to an issue? | No | [wg-gmd#8](https://github.com/chaoss/wg-gmd/issues/8) | None | No\n",
    "[Closed Issue Resolution Duration](https://github.com/chaoss/metrics/tree/master/activity-metrics/closed-issue-resolution-duration.md) | What is the duration of time for issues to be resolved? | Yes | [wg-gmd#7](https://github.com/chaoss/wg-gmd/issues/7) | None | No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"open_issues\"></a>\n",
    "### open issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "\n",
      "                            doc_count  value\n",
      "key                                         \n",
      "Jesus M. Gonzalez-Barahona          4      4\n",
      "Alberto Martín                      3      3\n",
      "others                              3      3\n",
      "Kapil Thangavelu                    2      2\n",
      "Alvaro del Castillo                 1      1\n",
      "Armijn Hemel                        1      1\n",
      "Brylie Christopher Oxley            1      1\n",
      "Daniel Izquierdo Cortazar           1      1\n",
      "Germán Poo-Caamaño                  1      1\n",
      "Lluis Josep Martinez                1      1\n",
      "Luis Cañas-Díaz                     1      1\n",
      "Maëlick                             1      1\n",
      "Michael Downey                      1      1\n",
      "Sachin S. Kamath                    1      1\n",
      "Samuel Ytterbrink                   1      1\n",
      "Total: 23\n",
      "\n",
      "                     doc_count  value\n",
      "key                                  \n",
      "others                      12     12\n",
      "@Bitergia                    3      3\n",
      "Bitergia                     3      3\n",
      "@DIAL-Community              1      1\n",
      "@amrita-university           1      1\n",
      "GNUmedia                     1      1\n",
      "T-Systems Iberia             1      1\n",
      "University of Oulu           1      1\n",
      "Total: 23\n",
      "\n",
      "            date_in_seconds  value\n",
      "key                               \n",
      "2016-02-01    1454284800000      1\n",
      "2016-03-01    1456790400000      4\n",
      "2016-04-01    1459468800000      0\n",
      "2016-05-01    1462060800000      0\n",
      "2016-06-01    1464739200000      1\n",
      "2016-07-01    1467331200000      0\n",
      "2016-08-01    1470009600000      0\n",
      "2016-09-01    1472688000000      2\n",
      "2016-10-01    1475280000000      2\n",
      "2016-11-01    1477958400000      1\n",
      "2016-12-01    1480550400000      1\n",
      "2017-01-01    1483228800000      0\n",
      "2017-02-01    1485907200000      1\n",
      "2017-03-01    1488326400000      0\n",
      "2017-04-01    1491004800000      0\n",
      "2017-05-01    1493596800000      2\n",
      "2017-06-01    1496275200000      0\n",
      "2017-07-01    1498867200000      0\n",
      "2017-08-01    1501545600000      0\n",
      "2017-09-01    1504224000000      0\n",
      "2017-10-01    1506816000000      0\n",
      "2017-11-01    1509494400000      2\n",
      "2017-12-01    1512086400000      1\n",
      "2018-01-01    1514764800000      0\n",
      "2018-02-01    1517443200000      3\n",
      "2018-03-01    1519862400000      1\n",
      "2018-04-01    1522540800000      0\n",
      "2018-05-01    1525132800000      1\n",
      "Total: 23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We are looking at all the issues that are open and were created between 2017-08-01 and 2018-05-22\n",
    "\n",
    "parent_id = 0\n",
    "child_id = 0.1\n",
    "s = Search(using=es, index=github_index)\n",
    "q1 = Q(\"match\", **{\"item_type\":\"issue\"})\n",
    "q2 = Q(\"match\", **{\"state\": \"open\"})\n",
    "q = q1 & q2\n",
    "s = s.query(q)\n",
    "\n",
    "# Number of open issues:\n",
    "agg = A(\"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# Open issues by the people that created them:\n",
    "agg = A(\"terms\", field=\"author_name\", missing=\"others\", size=max_size)\n",
    "agg.metric(child_id, \"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# Open issues by the organizations that created them:\n",
    "agg = A(\"terms\", field=\"user_org\", missing=\"others\", size=max_size)\n",
    "agg.metric(child_id, \"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# Open issues by the months in which they were created:\n",
    "period = \"month\" # should be one of month, week or year\n",
    "agg = A(\"date_histogram\", field=\"created_at\", interval=period)\n",
    "agg.metric(child_id, \"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# apply the range filter:\n",
    "s = s.filter(\"range\", **{\"created_at\":{\"gte\":start_date, \"lte\":end_date}})\n",
    "s = s.extra(size=0)\n",
    "\n",
    "response = s.execute()\n",
    "aggs = response.aggregations.to_dict()\n",
    "for i in range(parent_id):\n",
    "    try:\n",
    "        df = nf.buckets_to_df(aggs[str(i)]['buckets'])\n",
    "        print(df)\n",
    "        print(\"Total:\", df['value'].sum())\n",
    "    except:\n",
    "        print(aggs[str(i)]['value'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that we get the issues open by authors, by organizations and by the month in which they were created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"closed_issues\"></a>\n",
    "### closed issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "\n",
      "                            doc_count  value\n",
      "key                                         \n",
      "Alvaro del Castillo                27     27\n",
      "Alberto Martín                     20     20\n",
      "others                             10     10\n",
      "Jesus M. Gonzalez-Barahona          9      9\n",
      "Manrique Lopez                      9      9\n",
      "Santiago Dueñas                     9      9\n",
      "Daniel Izquierdo Cortazar           3      3\n",
      "David Pose Fernández                3      3\n",
      "Jose Miguel                         3      3\n",
      "Quan Zhou                           3      3\n",
      "Brylie Christopher Oxley            2      2\n",
      "Robin Muilwijk                      2      2\n",
      "Saad Bin Shahid                     2      2\n",
      "valerio                             2      2\n",
      "Andre Klapper                       1      1\n",
      "Bogdan Vasilescu                    1      1\n",
      "Bowen Chen                          1      1\n",
      "Cristian Baldi                      1      1\n",
      "Heather Booker                      1      1\n",
      "Lluis Josep Martinez                1      1\n",
      "Phillip Furtado                     1      1\n",
      "Sachin S. Kamath                    1      1\n",
      "Taewan Kim                          1      1\n",
      "Total: 113\n",
      "\n",
      "                     doc_count  value\n",
      "key                                  \n",
      "others                      44     44\n",
      "Bitergia                    39     39\n",
      "@Bitergia                   22     22\n",
      "GNUmedia                     2      2\n",
      "Geeky Engineer               2      2\n",
      "@amrita-university           1      1\n",
      "CMU                          1      1\n",
      "Samsung                      1      1\n",
      "T-Systems Iberia             1      1\n",
      "Total: 113\n",
      "\n",
      "            date_in_seconds  value\n",
      "key                               \n",
      "2016-01-01    1451606400000      1\n",
      "2016-02-01    1454284800000      1\n",
      "2016-03-01    1456790400000      4\n",
      "2016-04-01    1459468800000      1\n",
      "2016-05-01    1462060800000      0\n",
      "2016-06-01    1464739200000      2\n",
      "2016-07-01    1467331200000      2\n",
      "2016-08-01    1470009600000      1\n",
      "2016-09-01    1472688000000      5\n",
      "2016-10-01    1475280000000     10\n",
      "2016-11-01    1477958400000      6\n",
      "2016-12-01    1480550400000      3\n",
      "2017-01-01    1483228800000     11\n",
      "2017-02-01    1485907200000      0\n",
      "2017-03-01    1488326400000      7\n",
      "2017-04-01    1491004800000      2\n",
      "2017-05-01    1493596800000      2\n",
      "2017-06-01    1496275200000      1\n",
      "2017-07-01    1498867200000      1\n",
      "2017-08-01    1501545600000      0\n",
      "2017-09-01    1504224000000      9\n",
      "2017-10-01    1506816000000      8\n",
      "2017-11-01    1509494400000      9\n",
      "2017-12-01    1512086400000     11\n",
      "2018-01-01    1514764800000      3\n",
      "2018-02-01    1517443200000      4\n",
      "2018-03-01    1519862400000      7\n",
      "2018-04-01    1522540800000      2\n",
      "Total: 113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parent_id = 0\n",
    "child_id = 0.1\n",
    "s = Search(using=es, index=github_index)\n",
    "q1 = Q(\"match\", **{\"item_type\":\"issue\"})\n",
    "q2 = Q(\"match\", **{\"state\": \"closed\"})\n",
    "q = q1 & q2\n",
    "s = s.query(q)\n",
    "\n",
    "# Number of closed issues:\n",
    "agg = A(\"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# Closed issues by the people that created them:\n",
    "agg = A(\"terms\", field=\"author_name\", missing=\"others\", size=max_size)\n",
    "agg.metric(child_id, \"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# Closed issues by the organizations that created them:\n",
    "agg = A(\"terms\", field=\"user_org\", missing=\"others\", size=max_size)\n",
    "agg.metric(child_id, \"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# Closed issues by the months in which they were created:\n",
    "period = \"month\" # should be one of month, week or year\n",
    "agg = A(\"date_histogram\", field=\"created_at\", interval=period)\n",
    "agg.metric(child_id, \"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(parent_id, agg)\n",
    "parent_id += 1\n",
    "\n",
    "# apply the range filter:\n",
    "s = s.filter(\"range\", **{\"created_at\":{\"gte\":start_date, \"lte\":end_date}})\n",
    "s = s.extra(size=0)\n",
    "\n",
    "response = s.execute()\n",
    "aggs = response.aggregations.to_dict()\n",
    "for i in range(parent_id):\n",
    "    try:\n",
    "        df = nf.buckets_to_df(aggs[str(i)]['buckets'])\n",
    "        print(df)\n",
    "        print(\"Total:\", df['value'].sum())\n",
    "    except:\n",
    "        print(aggs[str(i)]['value'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that we get the issues closed by authors, by organizations and by the month in which they were created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue resolution efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"closed_issues\"></a>\n",
    "### open issue age\n",
    "\n",
    "As per the [discussion here](https://github.com/chaoss/metrics/blob/master/activity-metrics/open-issue-age.md), We'll calculate the percentile, mean, variance and create some visualisations for this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Search(using=es, index=github_index)\n",
    "q1 = Q(\"match\", **{\"item_type\":\"issue\"})\n",
    "q2 = Q(\"match\", **{\"state\": \"open\"})\n",
    "q = q1 & q2\n",
    "s = s.query(q)\n",
    "agg1 = A(\"percentiles\", field=\"time_open_days\")\n",
    "agg2 = A(\"extended_stats\", field=\"time_open_days\")\n",
    "s.aggs.bucket(\"open_issue_age_percentile\", agg1)\n",
    "s.aggs.bucket(\"open_issue_age_stats\", agg2)\n",
    "s = s.extra(size=0)\n",
    "response = s.execute()\n",
    "values = response.aggregations.open_issue_age_percentile.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pecentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1.0': 18.565400066375734, '5.0': 54.01599884033203, '25.0': 170.45999908447266, '50.0': 507.9200134277344, '75.0': 664.3300170898438, '95.0': 795.547021484375, '99.0': 810.472392578125}\n",
      "\n",
      "           value\n",
      "1.0    18.565400\n",
      "5.0    54.015999\n",
      "25.0  170.459999\n",
      "50.0  507.920013\n",
      "75.0  664.330017\n",
      "95.0  795.547021\n",
      "99.0  810.472393\n"
     ]
    }
   ],
   "source": [
    "percentiles = values.to_dict()\n",
    "print(percentiles)\n",
    "print()\n",
    "open_issue_age_percentile = pd.DataFrame.from_dict(percentiles, orient='index', columns=['value'])\n",
    "print(open_issue_age_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': 443.7830442760302,\n",
      " 'count': 23,\n",
      " 'max': 814.6699829101562,\n",
      " 'min': 9.640000343322754,\n",
      " 'std_deviation': 275.9541022453834,\n",
      " 'std_deviation_bounds': {'lower': -108.12516021473664,\n",
      "                          'upper': 995.691248766797},\n",
      " 'sum': 10207.010018348694,\n",
      " 'sum_of_squares': 6281163.309457999,\n",
      " 'variance': 76150.66654605552}\n"
     ]
    }
   ],
   "source": [
    "extended_stats = response.aggregations.open_issue_age_stats.to_dict()\n",
    "pprint(extended_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisations\n",
    "s = Search(using=es, index=github_index)\n",
    "q0 = Q(\"match_all\")\n",
    "q1 = Q(\"match\", **{\"item_type\":\"issue\"})\n",
    "q2 = Q(\"match\", **{\"state\": \"open\"})\n",
    "q = q0 & q1 & q2\n",
    "s = s.query(q)\n",
    "agg = A(\"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(\"num_open_issues\", agg)\n",
    "s = s.extra(_source=['time_open_days', 'id_in_repo'])\n",
    "s = s.extra(size=max_size)\n",
    "response = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            time_open_days\n",
      "id_in_repo                \n",
      "384                   9.64\n",
      "367                  50.21\n",
      "331                  88.27\n",
      "324                  95.15\n",
      "319                  99.84\n",
      "234                 170.13\n",
      "229                 170.79\n",
      "217                 173.08\n",
      "140                 373.01\n",
      "139                 374.73\n",
      "119                 451.62\n",
      "104                 507.92\n",
      "91                  557.90\n",
      "88                  569.10\n",
      "74                  586.77\n",
      "59                  612.92\n",
      "58                  617.82\n",
      "42                  710.84\n",
      "28                  788.04\n",
      "20                  793.81\n",
      "19                  795.16\n",
      "18                  795.59\n",
      "16                  814.67\n"
     ]
    }
   ],
   "source": [
    "open_issue_age = pd.DataFrame.from_records([hit['_source'] for hit in response.hits.hits], index=\"id_in_repo\")\n",
    "open_issue_age = open_issue_age.sort_values(by=\"time_open_days\", ascending=True)\n",
    "print(open_issue_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: create visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First response to issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed issue resolution duration (Time to resolution of closed issue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           value\n",
      "1.0     0.010000\n",
      "5.0     0.066000\n",
      "25.0    0.710000\n",
      "50.0    3.650000\n",
      "75.0   12.620000\n",
      "95.0  188.107996\n",
      "99.0  523.223621\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=github_index)\n",
    "q1 = Q(\"match\", **{\"item_type\":\"issue\"})\n",
    "q2 = Q(\"match\", **{\"state\": \"closed\"})\n",
    "q = q1 & q2\n",
    "s = s.query(q)\n",
    "agg1 = A(\"percentiles\", field=\"time_to_close_days\")\n",
    "agg2 = A(\"extended_stats\", field=\"time_to_close_days\")\n",
    "s.aggs.bucket(\"closed_issues_percentile\", agg1)\n",
    "s.aggs.bucket(\"closed_issues_stats\", agg2)\n",
    "s = s.extra(size=0)\n",
    "response = s.execute()\n",
    "values = response.aggregations.closed_issues_percentile.values\n",
    "percentiles = values.to_dict()\n",
    "closed_issue_percentile = pd.DataFrame.from_dict(percentiles, orient='index', columns=['value'])\n",
    "print(closed_issue_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the time to resolve an issue. We can see that more than 50% issues were resolved in under 4 days and more than 75% of the issues were resolved in under 13 days or approximately 2 weeks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg': 31.253982658819417,\n",
      " 'count': 113,\n",
      " 'max': 582.3300170898438,\n",
      " 'min': 0.0,\n",
      " 'std_deviation': 93.39081320398705,\n",
      " 'std_deviation_bounds': {'lower': -155.5276437491547,\n",
      "                          'upper': 218.0356090667935},\n",
      " 'sum': 3531.7000404465944,\n",
      " 'sum_of_squares': 1095948.062792196,\n",
      " 'variance': 8721.843990902002}\n"
     ]
    }
   ],
   "source": [
    "extended_stats = response.aggregations.closed_issues_stats.to_dict()\n",
    "pprint(extended_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving average\n",
    "Moving average: For time to issue resolution, we'll also look at the moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example query to get moving average \n",
    "{\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"my_date_histo\":{                \n",
    "            \"date_histogram\":{\n",
    "                \"field\":\"created_at\",\n",
    "                \"interval\":\"1M\"\n",
    "            },\n",
    "            \"aggs\":{\n",
    "                \"the_sum\":{\n",
    "                    \"sum\":{ \"field\": \"time_to_close_days\" } \n",
    "                },\n",
    "                \"the_movavg\":{\n",
    "                    \"moving_avg\":{ \"buckets_path\": \"the_sum\" } \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "s = Search(using=es, index=github_index)\n",
    "q1 = Q(\"match\", **{\"item_type\":\"issue\"})\n",
    "q2 = Q(\"match\", **{\"state\": \"closed\"})\n",
    "q = q1 & q2\n",
    "s = s.query(q)\n",
    "a = A(\"date_histogram\", field=\"created_at\", interval=\"1M\")\n",
    "a.metric(\"the_sum\", \"sum\", field=\"time_to_close_days\")\n",
    "a.metric(\"monthly_moving_average\", \"moving_avg\", buckets_path=\"the_sum\")\n",
    "s.aggs.bucket(\"the_histogram\", a)\n",
    "s = s.extra(size=0)\n",
    "response = s.execute()\n",
    "buckets = response.aggregations.the_histogram.to_dict()['buckets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date_in_seconds       value\n",
      "key                                    \n",
      "2016-01-01    1451606400000    0.570000\n",
      "2016-02-01    1454284800000    0.570000\n",
      "2016-03-01    1456790400000    8.435000\n",
      "2016-04-01    1459468800000    8.510000\n",
      "2016-05-01    1462060800000    0.000000\n",
      "2016-06-01    1464739200000    6.572500\n",
      "2016-07-01    1467331200000   44.860000\n",
      "2016-08-01    1470009600000   45.982000\n",
      "2016-09-01    1472688000000  159.188003\n",
      "2016-10-01    1475280000000  160.906003\n",
      "2016-11-01    1477958400000  300.138008\n",
      "2016-12-01    1480550400000  329.372011\n",
      "2017-01-01    1483228800000  332.380011\n",
      "2017-02-01    1485907200000    0.000000\n",
      "2017-03-01    1488326400000  311.332006\n",
      "2017-04-01    1491004800000  313.678006\n",
      "2017-05-01    1493596800000  179.372002\n",
      "2017-06-01    1496275200000  142.147999\n",
      "2017-07-01    1498867200000  137.923999\n",
      "2017-08-01    1501545600000    0.000000\n",
      "2017-09-01    1504224000000   43.258000\n",
      "2017-10-01    1506816000000  133.978000\n",
      "2017-11-01    1509494400000  145.562000\n",
      "2017-12-01    1512086400000  134.079999\n",
      "2018-01-01    1514764800000  148.871999\n",
      "2018-02-01    1517443200000  155.705999\n",
      "2018-03-01    1519862400000   85.135999\n",
      "2018-04-01    1522540800000   74.309999\n"
     ]
    }
   ],
   "source": [
    "df = nf.buckets_to_df(buckets)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            time_to_close_days\n",
      "id_in_repo                    \n",
      "265                       0.00\n",
      "204                       0.01\n",
      "26                        0.01\n",
      "354                       0.02\n",
      "133                       0.03\n",
      "142                       0.06\n",
      "113                       0.07\n",
      "17                        0.07\n",
      "80                        0.07\n",
      "89                        0.08\n",
      "72                        0.09\n",
      "210                       0.09\n",
      "144                       0.10\n",
      "92                        0.14\n",
      "116                       0.19\n",
      "257                       0.20\n",
      "103                       0.20\n",
      "123                       0.21\n",
      "90                        0.22\n",
      "63                        0.24\n",
      "122                       0.24\n",
      "216                       0.27\n",
      "187                       0.53\n",
      "327                       0.53\n",
      "107                       0.54\n",
      "8                         0.57\n",
      "95                        0.59\n",
      "221                       0.69\n",
      "110                       0.71\n",
      "94                        0.72\n",
      "...                        ...\n",
      "355                      11.29\n",
      "76                       12.62\n",
      "149                      13.75\n",
      "180                      13.98\n",
      "175                      14.76\n",
      "131                      14.97\n",
      "191                      15.62\n",
      "9                        16.30\n",
      "102                      20.28\n",
      "71                       20.87\n",
      "183                      23.05\n",
      "156                      24.19\n",
      "136                      24.44\n",
      "277                      26.18\n",
      "105                      29.00\n",
      "242                      32.10\n",
      "165                      42.63\n",
      "81                       50.26\n",
      "318                      52.87\n",
      "77                       71.78\n",
      "325                      74.28\n",
      "209                      81.49\n",
      "141                     158.00\n",
      "168                     182.18\n",
      "43                      197.00\n",
      "160                     202.49\n",
      "96                      339.89\n",
      "109                     428.43\n",
      "83                      536.15\n",
      "53                      582.33\n",
      "\n",
      "[113 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# visualisations\n",
    "s = Search(using=es, index=github_index)\n",
    "q0 = Q(\"match_all\")\n",
    "q1 = Q(\"match\", **{\"item_type\":\"issue\"})\n",
    "q2 = Q(\"match\", **{\"state\": \"closed\"})\n",
    "q = q0 & q1 & q2\n",
    "s = s.query(q)\n",
    "agg = A(\"cardinality\", field=\"id_in_repo\")\n",
    "s.aggs.bucket(\"num_closed_issues\", agg)\n",
    "s = s.extra(_source=['time_to_close_days', 'id_in_repo'])\n",
    "s = s.extra(size=max_size)\n",
    "response = s.execute()\n",
    "closed_issue_age = pd.DataFrame.from_records([hit['_source'] for hit in response.hits.hits], index=\"id_in_repo\")\n",
    "closed_issue_age = closed_issue_age.sort_values(by=\"time_to_close_days\", ascending=True)\n",
    "print(closed_issue_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Development\n",
    "Goal: Identify how effective the community is at merging new code into the codebase.\n",
    "\n",
    "Name | Question | Implemented | Issue | PR\n",
    "--- | --- | --- | --- | --- |\n",
    "[Code Commits](https://github.com/chaoss/metrics/tree/master/activity-metrics/code-commits.md) | What is the number of code commits? | Yes | None | None\n",
    "[Lines of Code Changed](https://github.com/chaoss/metrics/tree/master/activity-metrics/lines-of-code-changed.md) | What is the number of lines of code changed? | Yes | None | None\n",
    "[Code Reviews](https://github.com/chaoss/metrics/tree/master/activity-metrics/code-reviews.md) | What is the number of code reviews?\n",
    "[Code Merge Duration](https://github.com/chaoss/metrics/tree/master/activity-metrics/code-merge-duration.md) | What is the duration of time between code merge request and code commit?\n",
    "[Code Review Efficiency](https://github.com/chaoss/metrics/tree/master/activity-metrics/code-review-efficiency.md) | What is the number of merged code changes/number of abandoned code change requests?\n",
    "[Maintainer Response to Merge Request Duration](https://github.com/chaoss/metrics/tree/master/activity-metrics/maintainer-response-to-merge-request-duration.md) | What is the duration of time for a maintainer to make a first response to a code merge request?\n",
    "[Code Review Iteration](https://github.com/chaoss/metrics/tree/master/activity-metrics/code-review-iteration.md) | What is the number of iterations that occur before a merge request is accepted or declined?\n",
    "[Forks](activity-metrics/forks.md) | Forks are a concept in distributed version control systems like GitHub. It is a proxy for the approximate number of developers who have taken a shot at building and deploying the codebase *for development*.\n",
    "[Pull Requests Open](activity-metrics/pull-requests-open.md) | Number of open pull requests.\n",
    "[Pull Requests Closed](activity-metrics/pull-requests-made-closed.md) | Number of closed pull requests.\n",
    "[Pull Request Comment Duration](activity-metrics/pull-requests-comment-duration.md) | The difference between the timestamp of the pull request creation date and the most recent comment on the pull request.\n",
    "[Pull Request Comment Diversity](activity-metrics/pull-requests-comment-diversity.md) | Number of each people discussing each pull request.\n",
    "[Pull Request Comments](activity-metrics/pull-request-comments.md) | Number of comments on each pull request. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=git_index)\n",
    "#q = Q(\"match\", **{\"files\": 0})\n",
    "#s = s.query(~q)\n",
    "a = A(\"cardinality\", field=\"hash\", precision_threshold=2000)\n",
    "s.aggs.bucket(\"total_commits\", a)\n",
    "s = s.extra(_source=[\"hash\", \"commit_date\"])\n",
    "s = s.extra(sort={\"commit_date\":\"asc\"})\n",
    "response = s.execute()\n",
    "print(response.aggregations.total_commits.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you go to the [perceval github repo](https://github.com/chaoss/grimoirelab-perceval), you'll see that actually 1182 commit are present. That maybe because of some empty commit messages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date_in_seconds\n",
      "key                        \n",
      "2015-08-01    1438387200000\n",
      "2015-09-01    1441065600000\n",
      "2015-10-01    1443657600000\n",
      "2015-11-01    1446336000000\n",
      "2015-12-01    1448928000000\n",
      "2016-01-01    1451606400000\n",
      "2016-02-01    1454284800000\n",
      "2016-03-01    1456790400000\n",
      "2016-04-01    1459468800000\n",
      "2016-05-01    1462060800000\n",
      "2016-06-01    1464739200000\n",
      "2016-07-01    1467331200000\n",
      "2016-08-01    1470009600000\n",
      "2016-09-01    1472688000000\n",
      "2016-10-01    1475280000000\n",
      "2016-11-01    1477958400000\n",
      "2016-12-01    1480550400000\n",
      "2017-01-01    1483228800000\n",
      "2017-02-01    1485907200000\n",
      "2017-03-01    1488326400000\n",
      "2017-04-01    1491004800000\n",
      "2017-05-01    1493596800000\n",
      "2017-06-01    1496275200000\n",
      "2017-07-01    1498867200000\n",
      "2017-08-01    1501545600000\n",
      "2017-09-01    1504224000000\n",
      "2017-10-01    1506816000000\n",
      "2017-11-01    1509494400000\n",
      "2017-12-01    1512086400000\n",
      "2018-01-01    1514764800000\n",
      "2018-02-01    1517443200000\n",
      "2018-03-01    1519862400000\n",
      "2018-04-01    1522540800000\n",
      "2018-05-01    1525132800000\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=git_index)\n",
    "a = A(\"date_histogram\", field=\"commit_date\", interval=\"month\")\n",
    "s.aggs.bucket(\"commits_by_months\", a)\n",
    "response = s.execute()\n",
    "buckets = response.aggregations.commits_by_months.to_dict()['buckets']\n",
    "commits_by_month = nf.buckets_to_df(buckets)\n",
    "print(commits_by_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines of code changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines changed:  354358.0\n",
      "Total lines added:  265068.0\n",
      "Total lines removed:  89290.0\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=git_index)\n",
    "a1 = A(\"sum\", field=\"lines_changed\")\n",
    "a2 = A(\"sum\", field=\"lines_added\")\n",
    "a3 = A(\"sum\", field=\"lines_removed\")\n",
    "s.aggs.bucket(\"total_lines_changed\", a1)\n",
    "s.aggs.bucket(\"total_lines_added\", a2)\n",
    "s.aggs.bucket(\"total_lines_removed\", a3)\n",
    "s = s.extra(size=0)\n",
    "response = s.execute()\n",
    "\n",
    "print(\"Total lines changed: \", response.aggregations.total_lines_changed.value)\n",
    "print(\"Total lines added: \", response.aggregations.total_lines_added.value)\n",
    "print(\"Total lines removed: \", response.aggregations.total_lines_removed.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Growth\n",
    "Goal: Identify the size of the project community and whether it's growing, shrinking, or staying the same.\n",
    "\n",
    "Name | Question | Implemented | Issue | PR\n",
    "--- | --- | --- | --- | --- |\n",
    "[Contributors](https://github.com/chaoss/metrics/tree/master/activity-metrics/contributors.md) | What is the number of contributors? | Yes | None | None\n",
    "[New Contributors](https://github.com/chaoss/metrics/tree/master/activity-metrics/new-contributors.md) | What is the number of new contributors? | Yes | None | None\n",
    "[Contributing Organizations](https://github.com/chaoss/metrics/tree/master/activity-metrics/contributing-organizations.md) | What is the number of contributing organizations? | Yes | None | None\n",
    "[New Contributing Organizations](https://github.com/chaoss/metrics/tree/master/activity-metrics/new-contributing-organizations.md) | What is the number of new contributing organizations?\n",
    "[Sub-Projects](https://github.com/chaoss/metrics/tree/master/activity-metrics/sub-projects.md) | What is the number of sub-projects?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                average_files_changed  doc_count  lines_added  \\\n",
      "key                                                                             \n",
      "Santiago Dueñas                              2.139224       1494      91122.0   \n",
      "Valerio Cosentino                            2.223986        567      86338.0   \n",
      "Alberto Martín                               1.921569        102      43562.0   \n",
      "Alvaro del Castillo                          2.588235        102      30664.0   \n",
      "Jesus M. Gonzalez-Barahona                   2.054054         37       2058.0   \n",
      "valerio cosentino                            3.666667         12       2548.0   \n",
      "quan                                         5.600000         10       7186.0   \n",
      "Miguel Ángel Fernández                      11.333333          6         92.0   \n",
      "David Pose Fernández                         2.000000          4          8.0   \n",
      "camillem                                     1.000000          4          4.0   \n",
      "valerio                                      7.000000          4        246.0   \n",
      "David Esler                                  1.000000          2          4.0   \n",
      "Israel Herraiz                               3.000000          2        122.0   \n",
      "J. Manrique Lopez de la Fuente               4.000000          2        662.0   \n",
      "Luis Cañas Díaz                              2.000000          2          4.0   \n",
      "Prabhat                                      2.000000          2         28.0   \n",
      "Stephan Barth                               54.000000          2        108.0   \n",
      "anveshc05                                    3.000000          2        306.0   \n",
      "david                                        1.000000          2          6.0   \n",
      "\n",
      "                                lines_changed  lines_removed  \n",
      "key                                                           \n",
      "Santiago Dueñas                      123756.0        32634.0  \n",
      "Valerio Cosentino                    138388.0        52050.0  \n",
      "Alberto Martín                        45724.0         2162.0  \n",
      "Alvaro del Castillo                   31438.0          774.0  \n",
      "Jesus M. Gonzalez-Barahona             2176.0          118.0  \n",
      "valerio cosentino                      3406.0          858.0  \n",
      "quan                                   7308.0          122.0  \n",
      "Miguel Ángel Fernández                  380.0          288.0  \n",
      "David Pose Fernández                     20.0           12.0  \n",
      "camillem                                  8.0            4.0  \n",
      "valerio                                 324.0           78.0  \n",
      "David Esler                               6.0            2.0  \n",
      "Israel Herraiz                          136.0           14.0  \n",
      "J. Manrique Lopez de la Fuente          662.0            0.0  \n",
      "Luis Cañas Díaz                           8.0            4.0  \n",
      "Prabhat                                  56.0           28.0  \n",
      "Stephan Barth                           216.0          108.0  \n",
      "anveshc05                               338.0           32.0  \n",
      "david                                     8.0            2.0  \n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=git_index)\n",
    "a = A(\"terms\", field=\"author_name\", size=max_size)\n",
    "a.metric(\"lines_changed\", \"sum\", field=\"lines_changed\")\n",
    "a.metric(\"lines_added\", \"sum\", field=\"lines_added\")\n",
    "a.metric(\"lines_removed\", \"sum\", field=\"lines_removed\")\n",
    "a.metric(\"average_files_changed\", \"avg\", field=\"files\")\n",
    "s.aggs.bucket(\"contributors_contributions\", a)\n",
    "b = A(\"cardinality\", field=\"author_name\")\n",
    "s.aggs.bucket(\"total_contributors\", b)\n",
    "response = s.execute()\n",
    "buckets = response.aggregations.contributors_contributions.to_dict()['buckets']\n",
    "contributor_contributions = []\n",
    "for item in buckets:\n",
    "    bucket = {}\n",
    "    for key, val in item.items():\n",
    "        try:\n",
    "            bucket[key] = val['value']\n",
    "        except:\n",
    "            bucket[key] = val\n",
    "    contributor_contributions.append(bucket)\n",
    "contributor_contributions = pd.DataFrame.from_records(contributor_contributions, index=\"key\")\n",
    "print(contributor_contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total contributors:  19\n"
     ]
    }
   ],
   "source": [
    "print(\"Total contributors: \", response.aggregations.total_contributors.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New contributors\n",
    "\n",
    "For new contributors, we have to get the names and counts of the people who made commits to the project. [This](https://grimoirelab.gitbooks.io/tutorial/python/pandas-for-grimoirelab-indexes.html) tutorial of Grimoirelab actually gets the dates on which the authors made their first commits. Based on that we can get the months when the authors made their first commits and those authors will be the new authors for that month. We can do a similar thing for Year. (We can also get the authors by week, but there is little point in calculating that and it will be complex to calculate that too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors: \n",
      "                                 first_commit_date year-month\n",
      "author                                                       \n",
      "Santiago Dueñas                2015-08-18 18:08:27     2015-8\n",
      "Valerio Cosentino              2017-09-14 12:14:04     2017-9\n",
      "Alberto Martín                 2016-02-09 15:56:45     2016-2\n",
      "Alvaro del Castillo            2015-12-04 18:46:14    2015-12\n",
      "Jesus M. Gonzalez-Barahona     2015-12-31 19:16:25    2015-12\n",
      "valerio cosentino              2017-09-07 14:46:30     2017-9\n",
      "quan                           2016-04-01 12:16:29     2016-4\n",
      "Miguel Ángel Fernández         2018-02-12 12:56:11     2018-2\n",
      "David Pose Fernández           2017-11-03 08:23:54    2017-11\n",
      "camillem                       2016-03-28 11:08:04     2016-3\n",
      "valerio                        2017-10-10 16:27:29    2017-10\n",
      "David Esler                    2017-10-17 22:46:36    2017-10\n",
      "Israel Herraiz                 2018-01-09 15:40:57     2018-1\n",
      "J. Manrique Lopez de la Fuente 2016-03-05 08:04:02     2016-3\n",
      "Luis Cañas Díaz                2016-09-26 12:30:22     2016-9\n",
      "Prabhat                        2018-04-08 17:58:13     2018-4\n",
      "Stephan Barth                  2017-01-09 16:52:56     2017-1\n",
      "anveshc05                      2018-03-22 13:02:36     2018-3\n",
      "david                          2017-12-07 18:54:53    2017-12\n",
      "\n",
      "\n",
      "\n",
      "Number of new authors by month: \n",
      "2017-10    2\n",
      "2016-3     2\n",
      "2015-12    2\n",
      "2017-9     2\n",
      "2018-2     1\n",
      "2016-4     1\n",
      "2016-9     1\n",
      "2016-2     1\n",
      "2017-1     1\n",
      "2017-12    1\n",
      "2015-8     1\n",
      "2017-11    1\n",
      "2018-3     1\n",
      "2018-1     1\n",
      "2018-4     1\n",
      "Name: year-month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# new contributors by month\n",
    "s = Search(using=es, index=git_index)\n",
    "s.aggs.bucket(\"by_authors\", \"terms\", field=\"author_name\", size=10000).metric(\"first_commit\", \"min\", field=\"author_date\")\n",
    "s.sort(\"author_date\")\n",
    "response = s.execute()\n",
    "buckets = response.aggregations.by_authors.to_dict()['buckets']\n",
    "\n",
    "authors = []\n",
    "for bucket in buckets:\n",
    "    temp = {}\n",
    "    temp['first_commit_date'] = datetime.strptime(bucket['first_commit']['value_as_string'][:-5], \"%Y-%m-%dT%H:%M:%S\")\n",
    "    temp['author'] = bucket['key']\n",
    "    temp['year-month'] = str(temp['first_commit_date'].year) + \"-\" + str(temp['first_commit_date'].month)\n",
    "    authors.append(temp)\n",
    "authors = pd.DataFrame.from_records(authors, index=\"author\")\n",
    "print(\"Authors: \")\n",
    "print(authors)\n",
    "print(\"\\n\\n\")\n",
    "print(\"Number of new authors by month: \")\n",
    "print(authors['year-month'].value_counts(sort=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributing Organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       @Bitergia \n",
      "1                         Bitergia\n",
      "2                         GNUmedia\n",
      "3              @amrita-university \n",
      "4            BBVA Data & Analytics\n",
      "5                   Geeky Engineer\n",
      "6                 T-Systems Iberia\n",
      "7                 @DIAL-Community \n",
      "8                              CMU\n",
      "9                   IIIT Hyderabad\n",
      "10                          Orange\n",
      "11                            SUSE\n",
      "12                         Samsung\n",
      "13              University of Oulu\n",
      "14    http://www.aeva.in/team.html\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es, index=github_index)\n",
    "a = A(\"terms\", field=\"user_org\", size=max_size)\n",
    "s.aggs.bucket(\"contributing_orgs\", a)\n",
    "s = s.extra(size=0)\n",
    "response = s.execute()\n",
    "buckets = response.aggregations.contributing_orgs.to_dict()['buckets']\n",
    "organizations = pd.Series([item['key'] for item in buckets])\n",
    "print(organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Search(using=es, index=github_index)\n",
    "a = A(\"terms\", field=\"user_org\", missing=\"Others\", size=max_size)\n",
    "a.metric(\"users\", \"terms\", field=\"author_name\")\n",
    "s.aggs.bucket(\"users_by_org\", a)\n",
    "response = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_count': 164,\n",
       "  'key': '@Bitergia ',\n",
       "  'users': {'buckets': [{'doc_count': 131, 'key': 'valerio'},\n",
       "    {'doc_count': 33, 'key': 'Alberto Martín'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 122,\n",
       "  'key': 'Others',\n",
       "  'users': {'buckets': [{'doc_count': 32, 'key': 'Jesus M. Gonzalez-Barahona'},\n",
       "    {'doc_count': 31, 'key': 'Santiago Dueñas'},\n",
       "    {'doc_count': 8, 'key': 'Jose Miguel'},\n",
       "    {'doc_count': 7, 'key': 'Quan Zhou'},\n",
       "    {'doc_count': 6, 'key': 'David Pose Fernández'},\n",
       "    {'doc_count': 4, 'key': 'Keanu Nichols'},\n",
       "    {'doc_count': 2, 'key': 'David Esler'},\n",
       "    {'doc_count': 2, 'key': 'Gustavo Silva'},\n",
       "    {'doc_count': 2, 'key': 'Kapil Thangavelu'},\n",
       "    {'doc_count': 2, 'key': 'Robin Muilwijk'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 12}},\n",
       " {'doc_count': 79,\n",
       "  'key': 'Bitergia',\n",
       "  'users': {'buckets': [{'doc_count': 61, 'key': 'Alvaro del Castillo'},\n",
       "    {'doc_count': 10, 'key': 'Manrique Lopez'},\n",
       "    {'doc_count': 4, 'key': 'Daniel Izquierdo Cortazar'},\n",
       "    {'doc_count': 2, 'key': 'Luis Cañas-Díaz'},\n",
       "    {'doc_count': 2, 'key': 'Miguel Ángel Fernández'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 3,\n",
       "  'key': 'GNUmedia',\n",
       "  'users': {'buckets': [{'doc_count': 3, 'key': 'Brylie Christopher Oxley'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 2,\n",
       "  'key': '@amrita-university ',\n",
       "  'users': {'buckets': [{'doc_count': 2, 'key': 'Sachin S. Kamath'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 2,\n",
       "  'key': 'BBVA Data & Analytics',\n",
       "  'users': {'buckets': [{'doc_count': 2, 'key': 'Israel Herraiz'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 2,\n",
       "  'key': 'Geeky Engineer',\n",
       "  'users': {'buckets': [{'doc_count': 2, 'key': 'Saad Bin Shahid'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 2,\n",
       "  'key': 'T-Systems Iberia',\n",
       "  'users': {'buckets': [{'doc_count': 2, 'key': 'Lluis Josep Martinez'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': '@DIAL-Community ',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Michael Downey'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': 'CMU',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Bogdan Vasilescu'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': 'IIIT Hyderabad',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Anvesh Chaturvedi'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': 'Orange',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Nicolas Lamirault'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': 'SUSE',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Stephan Barth'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': 'Samsung',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Taewan Kim'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': 'University of Oulu',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Maëlick'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}},\n",
       " {'doc_count': 1,\n",
       "  'key': 'http://www.aeva.in/team.html',\n",
       "  'users': {'buckets': [{'doc_count': 1, 'key': 'Prabhat'}],\n",
       "   'doc_count_error_upper_bound': 0,\n",
       "   'sum_other_doc_count': 0}}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.aggregations.users_by_org.to_dict()['buckets']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
